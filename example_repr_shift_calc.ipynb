{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "analyzed-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, datasets, transforms\n",
    "from scipy.stats import wasserstein_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-pattern",
   "metadata": {},
   "source": [
    "# Representation shift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-offense",
   "metadata": {},
   "source": [
    "Example code on how to calculate Representation Shift using Wasserstein distance. \n",
    "\n",
    "In this example, we are using a model pre-trained on Imagenet, and calculate the representation shift between in-distribution data (train and validation data respectivly from the TinyImageNet dataset) and between out-of-distribution data (TinyImageNet vs CIFAR10). \n",
    "\n",
    "Requirements: download Tiny ImageNet data, found here: https://www.kaggle.com/mikewallace250/tiny-imagenet-challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-graphics",
   "metadata": {},
   "source": [
    "## Prepare data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hispanic-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = 'data/TinyImageNet'\n",
    "path_to_store_downloaded_data = 'data'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "palestinian-kentucky",
   "metadata": {},
   "source": [
    "Using model pretrained on Imagenet, removing the final fully connected layer to get output from penultimate layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "selected-toner",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "setattr(model, 'fc', Identity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "determined-seventh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Download test data from open datasets.\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "tiny_imagenet_data = datasets.ImageFolder(root=f'{path_to_data}/train', transform=trans)\n",
    "tiny_imagenet_data_val = datasets.ImageFolder(root=f'{path_to_data}/val', transform=trans)\n",
    "cifar_data = datasets.CIFAR10(root=path_to_store_downloaded_data, train=False, download=True, transform=trans)\n",
    "\n",
    "reference_dataloader = torch.utils.data.DataLoader(tiny_imagenet_data, batch_size=1)\n",
    "indist_dataloader = torch.utils.data.DataLoader(tiny_imagenet_data_val, batch_size=1)\n",
    "outdist_dataloader = torch.utils.data.DataLoader(cifar_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-allowance",
   "metadata": {},
   "source": [
    "## Calculate Representation Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "simplified-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activations(model, dataloader, max_samples=1000):\n",
    "    \"\"\"\n",
    "    Iterate though each (subset of) dataset and store activations.\n",
    "    \n",
    "    Parameters:\n",
    "        model (torch.model): the model to evaluate, output representation of input image with size D\n",
    "        dataloader (torch.utils.data.DataLoader): Dataloader, with batch size 1\n",
    "        max_samples (int): number of samples to evaluate, N\n",
    "\n",
    "    Returns:\n",
    "        activations (numpy.array): Array of size NxD\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "\n",
    "    activations = []\n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(dataloader):\n",
    "            if idx >= max_samples:\n",
    "                break\n",
    "            print(f'\\r{idx}/{min(len(dataloader), max_samples)}', end=\"\")\n",
    "            out = model(batch[0])\n",
    "            activations.extend(out.numpy())\n",
    "    \n",
    "    return np.asarray(activations)\n",
    "\n",
    "def representation_shift(act_ref, act_test):\n",
    "    \"\"\"\n",
    "    Calculate representation shift using Wasserstein distance\n",
    "    \n",
    "    Parameters:\n",
    "        act_ref (numpy.array): Array of size NxD\n",
    "        act_test (numpy.array): Array of size NxD\n",
    "\n",
    "    Returns:\n",
    "        representation_shift (float): Mean Wasserstein distance over all channels (D) \n",
    "    \"\"\"\n",
    "    wass_dist = [wasserstein_distance(act_ref[:, channel], act_test[:, channel]) for channel in range(act_ref.shape[1])]\n",
    "    return np.asarray(wass_dist).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "educated-gambling",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999/1000"
     ]
    }
   ],
   "source": [
    "# Get activations for a subset of each dataset\n",
    "activations_ref = extract_activations(model, reference_dataloader)\n",
    "activations_indist = extract_activations(model, indist_dataloader)\n",
    "activations_outdist = extract_activations(model, outdist_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "clean-usage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Representation shift, in-distribution: 0.1595269632828995\n",
      "Representation shift, out-of-distribution: 0.2402791791188115\n"
     ]
    }
   ],
   "source": [
    "wass_dist_indist = representation_shift(activations_ref, activations_indist)\n",
    "wass_dist_outdist =  representation_shift(activations_ref, activations_outdist)\n",
    "\n",
    "print('Representation shift, in-distribution:', wass_dist_indist)\n",
    "print('Representation shift, out-of-distribution:', wass_dist_outdist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
